# 共享CFO项目开发进度日志

> 记录每次开发的进展，方便下次继续

---

## 2026-01-18 会话记录

### 时间
开始时间：约 09:00
结束时间：进行中

### 本次会议完成的工作

#### 1. 部署环境确认
- **ECS服务器**：120.78.5.4 (Ubuntu 22.04)
- **SSH连接**：使用密钥认证 `~/.ssh/id_ed25519`
- **MongoDB**：已在ECS上自建安装（节省成本，不再使用云MongoDB）

#### 2. 项目结构
```
/opt/shared-cfo/
├── crawler/          # 爬虫目录
├── backend/          # 后端目录
├── api/              # API目录
├── logs/             # 日志目录
├── venv/             # Python虚拟环境
├── .env              # 环境变量配置
└── crawler.py        # 爬虫脚本
```

#### 3. MongoDB配置
- 地址：localhost:27017
- 用户：cfo_user
- 数据库：shared_cfo
- 集合：policies
- 状态：✅ 运行中

#### 4. 爬虫数据
- 当前数据量：5条示例数据
- 数据来源：
  - 国家税务总局（增值税、所得税政策）
  - 北京市税务局
  - 上海市税务局

### 当前任务状态

| 任务 | 状态 | 说明 |
|------|------|------|
| MongoDB部署 | ✅ 完成 | ECS自建 |
| 爬虫代码 | ✅ 完成 | 已有数据 |
| Qdrant部署 | ⏳ 待完成 | 需要部署向量数据库 |
| 后端API | ⏳ 进行中 | FastAPI框架代码已准备 |
| 向量化服务 | ⏳ 待完成 | 需要GLM API |
| RAG问答 | ⏳ 待完成 | 依赖向量数据库 |
| 前端开发 | ⏳ 待完成 | Vue3 |

### 下次会话计划

1. **部署Qdrant向量数据库**
   ```bash
   docker run -d --name qdrant -p 6333:6333 qdrant/qdrant:latest
   ```

2. **上传后端API代码**
   - 位置：`C:\Users\CINDEMAN\Claude项目\共享CFO\backend`
   - 上传到ECS：`/opt/shared-cfo/backend`

3. **配置GLM API Key**
   - 需要获取智谱AI的API Key
   - 配置到 `.env` 文件

4. **实现向量化入库**
   - 将MongoDB中的政策数据向量化
   - 存入Qdrant

5. **实现RAG问答接口**
   - 用户问题 → 向量检索 → GLM生成答案

### 重要命令速查

```bash
# SSH连接
ssh -i "C:\Users\CINDEMAN\.ssh\id_ed25519" root@120.78.5.4

# 查看MongoDB数据
mongosh 'mongodb://cfo_user:840307%40whY@localhost:27017/shared_cfo?authSource=admin'

# 查看爬虫日志
tail -f /opt/shared-cfo/logs/crawler.log

# 激活Python环境
cd /opt/shared-cfo && source venv/bin/activate
```

### 待解决问题

1. **爬虫404问题**：国家税务总局网站结构可能变化，需要更新爬虫逻辑
2. **GLM API Key**：需要申请智谱AI的API密钥
3. **Qdrant部署**：需要在ECS上安装Docker并部署Qdrant

---

## 会话历史

### 2026-01-17
- 初始项目规划
- 购买阿里云ECS和MongoDB（后改为自建）

---

### 2026-01-18 会话记录（第二次）

#### 时间
开始时间：约 09:30
结束时间：约 10:20

#### 本次会话完成的工作

##### 1. 爬虫问题解决（重点）
- **问题**：国家税务总局网站有严格反爬虫，使用requests无法获取数据
- **解决方案**：安装Playwright浏览器自动化工具
- **结果**：成功爬取58条政策数据，数据库共63条

##### 2. 向量数据库部署
- **问题**：Qdrant Docker镜像因网络问题无法拉取
- **解决方案**：改用ChromaDB本地向量数据库
- **状态**：✅ 已安装ChromaDB 1.4.1

##### 3. 后端API搭建
- **框架**：FastAPI 0.128.0
- **状态**：✅ 已启动，监听端口8000
- **健康检查**：`http://120.78.5.4:8000/health` 返回正常

#### 项目当前状态

| 任务 | 状态 | 说明 |
|------|------|------|
| MongoDB部署 | ✅ 完成 | ECS自建，63条数据 |
| 爬虫（Playwright） | ✅ 完成 | 58条新数据 |
| ChromaDB向量库 | ✅ 完成 | 本地部署 |
| 后端API | ✅ 完成 | FastAPI运行中 |
| 向量化服务 | ⏳ 待完成 | 需要GLM API Key |
| RAG问答接口 | ⏳ 待完成 | 依赖向量化 |
| 前端开发 | ⏳ 待完成 | Vue3 |

#### 重要文件位置

```
/opt/shared-cfo/
├── crawler_playwright.py    # Playwright爬虫（工作正常）
├── backend/
│   └── app/
│       ├── main.py          # FastAPI主入口
│       ├── config.py        # 配置文件
│       └── api/routes/      # API路由
├── venv/                    # Python虚拟环境
└── logs/                    # 日志目录
```

#### 下次会话优先任务

1. **配置GLM API Key**
   - 访问 https://open.bigmodel.cn/ 注册获取
   - 添加到 `/opt/shared-cfo/.env`

2. **实现向量化服务**
   - 将63条政策文本向量化
   - 存入ChromaDB

3. **实现RAG问答接口**
   - 用户问题 → 向量检索 → GLM生成结构化答案

4. **开发简版前端**
   - Vue3 + Element Plus
   - 实现问答界面

#### API测试命令

```bash
# SSH连接
ssh -i "C:\Users\CINDEMAN\.ssh\id_ed25519" root@120.78.5.4

# 测试健康检查
curl http://localhost:8000/health

# 启动API（后台）
cd /opt/shared-cfo/backend && source ../venv/bin/activate && python -m app.main

# 运行爬虫获取更多数据
cd /opt/shared-cfo && source venv/bin/activate && python crawler_playwright.py
```

#### 数据统计

- 总政策数：63条
- 主要来源：国家税务总局
- 数据格式：包含标题、内容、URL、税种标签等

---

## 会话历史

### 2026-01-18（第一次）
- MongoDB部署完成
- 爬虫初始版本遇到403反爬虫问题
- Playwright安装

### 2026-01-17
- 初始项目规划
- 阿里云ECS购买

---

*最后更新：2026-01-18 10:20*
